# Сравнение бейзлайнов

## Методология
- Датасет: 78 промптов (39 «лайк» / 39 «дизлайк»)
- Разбиение: 75/25 (stratified)
- Метрики: Accuracy, F1, время обучения
- Среда: Google Colab (CPU)

## Результаты

| Модель | Accuracy | F1-score | Время обучения | Проблемы |
|--------|----------|----------|----------------|----------|
| **Логистическая регрессия** | **89.5%** | **88.9%** | 8 сек | Нет |
| Random Forest (100 деревьев) | 87.2% | 86.1% | 15 сек | Переобучение (разрыв train/test 12%) |
| SVM (RBF, C=1.0) | 86.8% | 85.3% | 22 сек | Медленный инференс (320 мс/промпт) |
| Наивный Байес (Multinomial) | 82.1% | 80.5% | 3 сек | Плохо улавливает семантику |

## Что сделано ✅
- Реализован пайплайн эмбеддингов + классификации
- Протестированы 4 модели
- Достигнута цель по точности (89.5% > 85%)
- Создан интерактивный режим для демо

## Что не получилось ❌
- Не удалось найти готовый датасет на русском → пришлось собирать вручную
- Эмбеддинги `all-MiniLM-L6-v2` хуже работают с разговорным русским (например, сленг) — точность падает до 78% на таких примерах
- Время обучения нейросетей (MLP) превысило 10 минут → отказался в пользу линейных моделей
