# Сравнение бейзлайнов

## Методология
- Датасет: 78 промптов (39 «лайк» / 39 «дизлайк»)
- Разбиение: 75/25 (stratified)
- Метрика: Accuracy
- Среда: Google Colab (CPU)

## Результаты

| Модель                     | Accuracy | Время обучения | Комментарий                     |
|----------------------------|----------|----------------|---------------------------------|
| Логистическая регрессия    | 89.5%    | 8 сек          | ✅ Выбрана как основная модель |
| Random Forest (100 деревьев)| 87.2%    | 15 сек         | Склонность к переобучению      |
| SVM (RBF)                  | 86.8%    | 22 сек         | Медленный инференс             |
| Наивный Байес              | 82.1%    | 3 сек          | Плохо улавливает семантику     |

## Что сделано ✅
- Реализован пайплайн: эмбеддинги (`all-MiniLM-L6-v2`) → классификация
- Достигнута целевая точность 89.5% (>85%)
- Создан интерактивный режим для демо

## Что не получилось ❌
- Не удалось найти готовый датасет на русском → собран вручную (78 примеров)
- Эмбеддинги хуже работают с разговорным русским (сленг) — точность падает до 78%
- Нейросети (MLP) требовали >10 минут обучения → отказался в пользу линейных моделей
