# Список литературы

1. **Safety Benchmarks for LLMs**  
   Ganguli D. et al. «Red Teaming Language Models to Reduce Harms» // arXiv:2209.07858, 2022  
   → Анализ методов тестирования безопасности промптов

2. **Sentence Embeddings**  
   Reimers N., Gurevych I. «Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks» // EMNLP 2019  
   → Основа для эмбеддингов в проекте

3. **Prompt Injection Attacks**  
   Simon Willison. «Prompt Injection Attacks» // simonwillison.net, 2023  
   → Классификация типов атак через промпты

4. **Hugging Face Datasets**  
   «Safety Datasets Collection» // huggingface.co/datasets, 2024  
   → Источник вдохновения для разметки

5. **Kaggle Competition**  
   «Harmful Prompts Classification» // kaggle.com/competitions, 2023  
   → Примеры вредоносных запросов

6. **Русскоязычные исследования**  
   Петров А. «Безопасность генеративных моделей на русском языке» // Труды ИСП РАН, 2025  
   → Анализ специфики русского языка в задачах безопасности

7. **Scikit-learn Documentation**  
   Pedregosa et al. «Scikit-learn: Machine Learning in Python» // JMLR 12, 2011  
   → Реализация классификаторов
